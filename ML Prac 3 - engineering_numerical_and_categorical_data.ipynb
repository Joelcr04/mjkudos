{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Numerical and Categorical Data\n",
    "\n",
    "This notebook show cases some of the common methods for feature extraction and engineering on numerical and categorical data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Set Default directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\rahul\\\\OneDrive\\\\BIZOP\\\\AFI Tech Bangalore\\\\TRAINING CONTENT\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# pandas display data frames as tables\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting params\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (30, 10),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engineering : Numerical Data \n",
    "The dataset utilized for numerical features is the credit card default dataset from UCI (available [here](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "credit_df = pd.read_excel('credit_default.xls',\n",
    "                             skiprows=1,index_col=0)\n",
    "credit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract Raw Features\n",
    "Attributes which are useful in their raw form itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df[['LIMIT_BAL','BILL_AMT1',\n",
    "                   'BILL_AMT2','BILL_AMT3',\n",
    "                   'BILL_AMT4','BILL_AMT5',\n",
    "                   'BILL_AMT6']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts\n",
    "Based on requirements, count of events is also a useful attribute.\n",
    "For instance, in the credit defaulters dataset, knowing *how many times a person has defaulted* may be a useful feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def default_month_count(row):\n",
    "    count = 0 \n",
    "    for i in [0,2,3,4,5,6]:\n",
    "        if row['PAY_'+str(i)] > 0:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df['number_of_default_months'] = credit_df.apply\\\n",
    "(default_month_count,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df[['number_of_default_months']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization\n",
    "Occurance or absence of an event is also a useful feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df['has_ever_defaulted'] = credit_df.number_of_default_months.apply\\\n",
    "(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df[['number_of_default_months','has_ever_defaulted']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Binning\n",
    "Also known as quantization, helps in transforming continuous features such as age and income onto discrete scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.AGE.plot(kind='hist',bins=20)\n",
    "plt.title('Age Histogram', fontsize=24)\n",
    "plt.xlabel('Age', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Width Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed Width Bins :\n",
    "\n",
    "``` \n",
    "Age Range: Bin\n",
    "---------------\n",
    " 0 -  9  : 0\n",
    "10 - 19  : 1\n",
    "20 - 29  : 2\n",
    "30 - 39  : 3\n",
    "  ... and so on\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a bin label to each row\n",
    "credit_df['age_bin_fixed'] = credit_df.AGE.apply(lambda age: \\\n",
    "                                                 np.floor(age/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df[['AGE','age_bin_fixed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.age_bin_fixed.plot(kind='hist',bins=20)\n",
    "plt.title('Age Histogram', fontsize=24)\n",
    "plt.xlabel('Age', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantile Based Binning\n",
    "* 4-Quantile Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quantile binning\n",
    "quantile_list = [0, .25, .5, .75, 1]\n",
    "quantiles = credit_df.AGE.quantile(quantile_list)\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Quartile Ranges on the Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "credit_df.AGE.plot(kind='hist',bins=60)\n",
    "\n",
    "for quantile in quantiles:\n",
    "    qvl = plt.axvline(quantile, color='r')\n",
    "ax.legend([qvl], ['Quantiles'], fontsize=10)\n",
    "\n",
    "ax.set_title('Age Histogram with Quantiles', fontsize=12)\n",
    "ax.set_xlabel('Age', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Quantile Bin Labels\n",
    "quantile_labels = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "credit_df['age_quantile_range'] = pd.qcut(credit_df['AGE'],\n",
    "                                          q=quantile_list)\n",
    "credit_df['age_quantile_label'] = pd.qcut(credit_df['AGE'],\n",
    "                                          q=quantile_list,\n",
    "                                          labels=quantile_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df[['AGE','age_quantile_range','age_quantile_label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engineering : Categorical Data\n",
    "We have utilized multiple publicly available datasets to better understand categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df = pd.read_csv('battles.csv')\n",
    "battles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df[['name','year','attacker_king','attacker_1']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Nominal Features\n",
    "Categorical attributes which ***do not*** have any intrinsic ordering amongst them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "attacker_le = LabelEncoder()\n",
    "attacker_labels = attacker_le.fit_transform(battles_df.attacker_1)\n",
    "attacker_mappings = {index: label for index, label in enumerate(attacker_le.classes_)}\n",
    "attacker_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels\n",
    "battles_df['attacker1_label'] = attacker_labels\n",
    "battles_df[['name','year','attacker_king','attacker_1','attacker1_label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Ordinal Features\n",
    "Categorical attributes which ***have*** an intrinsic ordering amongst them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.DataFrame(data={\n",
    "                            'items_sold':abs(np.random.randn(7)*100),\n",
    "                             'day_of_week':['Monday', 'Tuesday',\n",
    "                                            'Wednesday', 'Thursday', \n",
    "                                            'Friday', 'Saturday', \n",
    "                                            'Sunday']})\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_map = {'Monday': 1, 'Tuesday': 2, \n",
    "           'Wednesday': 3, 'Thursday': 4, \n",
    "           'Friday': 5, 'Saturday': 6, \n",
    "           'Sunday' : 7}\n",
    "\n",
    "sales_df['weekday_label'] = sales_df['day_of_week'].map(day_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categoricals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "day_le = LabelEncoder()\n",
    "day_labels = day_le.fit_transform(sales_df['day_of_week'])\n",
    "sales_df['label_encoder_day_label'] = day_labels\n",
    "\n",
    "sales_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode day labels using one-hot encoding scheme\n",
    "day_ohe = OneHotEncoder()\n",
    "day_feature_arr = day_ohe.fit_transform(sales_df[['label_encoder_day_label']]).toarray()\n",
    "day_feature_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_feature_labels = list(day_le.classes_)\n",
    "day_features = pd.DataFrame(day_feature_arr, columns=day_feature_labels)\n",
    "day_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_ohe_df = pd.concat([sales_df, day_features], axis=1)\n",
    "sales_ohe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dummy_features = pd.get_dummies(sales_df['day_of_week'], drop_first=True)\n",
    "pd.concat([sales_df[['day_of_week','items_sold']], day_dummy_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
